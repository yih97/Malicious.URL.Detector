{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T03:22:50.453151Z",
     "start_time": "2025-02-28T03:22:48.972031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from autogluon.multimodal import MultiModalPredictor\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ],
   "id": "c8cdca4a701afaf",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T03:22:56.354590Z",
     "start_time": "2025-02-28T03:22:50.456663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ì—”íŠ¸ë¡œí”¼ íŠ¹ì„±ì´ ì¶”ê°€ëœ ìƒˆ ë°ì´í„°ë¥¼ CSV íŒŒì¼ì—ì„œ ì½ì–´ì˜µë‹ˆë‹¤.\n",
    "try:\n",
    "    final_train = pd.read_csv('../../data/preprocessed_data/final_train_ver2.csv')\n",
    "    final_test = pd.read_csv('../../data/preprocessed_data/final_test_ver2.csv')\n",
    "    print(\"ë°ì´í„° ë¡œë“œ ì„±ê³µ.\")\n",
    "except Exception as e:\n",
    "    print(\"ë°ì´í„° ë¡œë“œ ì—ëŸ¬:\", e)\n",
    "    final_train = pd.DataFrame()\n",
    "    final_test = pd.DataFrame()\n"
   ],
   "id": "8f956f4b06f9fab0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ë¡œë“œ ì„±ê³µ.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T03:22:56.384597Z",
     "start_time": "2025-02-28T03:22:56.382343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ê° ì»¬ëŸ¼ì˜ íƒ€ì…ì„ ì§€ì •í•©ë‹ˆë‹¤. ìƒˆë¡œ ì¶”ê°€ëœ ì—”íŠ¸ë¡œí”¼ íŠ¹ì„±ë„ í¬í•¨ì‹œí‚µë‹ˆë‹¤.\n",
    "try:\n",
    "    # ê¸°ì¡´ íŠ¹ì„±ê³¼ ì—”íŠ¸ë¡œí”¼ íŠ¹ì„±ì„ ëª¨ë‘ í¬í•¨í•©ë‹ˆë‹¤\n",
    "    # ì‹¤ì œ ì„ íƒëœ íŠ¹ì„±ì— ë”°ë¼ ì´ ëª©ë¡ì„ ì¡°ì •í•´ì•¼ í•©ë‹ˆë‹¤\n",
    "    column_types = {\n",
    "        'URL': 'text',\n",
    "        'label': 'categorical',\n",
    "        'digit_ratio': 'numerical',\n",
    "        'special_char_count': 'numerical',\n",
    "        'subdomain_count': 'numerical',\n",
    "        'length': 'numerical',\n",
    "        # ì¶”ê°€ëœ ì—”íŠ¸ë¡œí”¼ íŠ¹ì„±\n",
    "        'url_entropy': 'numerical',\n",
    "        'domain_entropy': 'numerical',\n",
    "        'path_entropy': 'numerical',\n",
    "        'query_entropy': 'numerical',\n",
    "        'subdomain_entropy': 'numerical',\n",
    "        'tld_entropy': 'numerical',\n",
    "        'main_domain_entropy': 'numerical'\n",
    "    }\n",
    "\n",
    "    # ì‹¤ì œ ë°ì´í„°ì…‹ì— ìˆëŠ” ì»¬ëŸ¼ë§Œ í¬í•¨í•˜ë„ë¡ í•„í„°ë§\n",
    "    column_types = {col: type for col, type in column_types.items() if col in final_train.columns}\n",
    "\n",
    "    print(\"ì»¬ëŸ¼ íƒ€ì… ì„¤ì • ì„±ê³µ.\")\n",
    "    print(f\"ì‚¬ìš©ë˜ëŠ” ì»¬ëŸ¼: {list(column_types.keys())}\")\n",
    "except Exception as e:\n",
    "    print(\"ì»¬ëŸ¼ íƒ€ì… ì„¤ì • ì—ëŸ¬:\", e)\n",
    "    column_types = {}\n"
   ],
   "id": "44c5b533d26daceb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì»¬ëŸ¼ íƒ€ì… ì„¤ì • ì„±ê³µ.\n",
      "ì‚¬ìš©ë˜ëŠ” ì»¬ëŸ¼: ['URL', 'label', 'digit_ratio', 'special_char_count', 'subdomain_count', 'length', 'url_entropy', 'path_entropy', 'subdomain_entropy']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T03:22:56.845114Z",
     "start_time": "2025-02-28T03:22:56.419971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train ë°ì´í„°ì˜ 'label' ì»¬ëŸ¼ì„ ê¸°ì¤€ìœ¼ë¡œ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ë¥¼ ê³„ì‚°í•˜ê³  ì •ê·œí™”í•©ë‹ˆë‹¤.\n",
    "try:\n",
    "    weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(final_train['label']),\n",
    "        y=final_train['label'].values\n",
    "    )\n",
    "    weights = weights / weights.sum()  # ê°€ì¤‘ì¹˜ ì •ê·œí™” (í•©ê³„ 1)\n",
    "    weights = list(weights)\n",
    "    print(\"\\nê³„ì‚°ëœ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜:\", weights)\n",
    "except Exception as e:\n",
    "    print(\"í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° ì—ëŸ¬:\", e)\n",
    "    weights = []\n"
   ],
   "id": "df81bb5b23345f36",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ê³„ì‚°ëœ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜: [0.2237147207970887, 0.7762852792029113]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T03:22:56.876430Z",
     "start_time": "2025-02-28T03:22:56.873859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# AutoGluon MultiModalPredictorë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "try:\n",
    "    predictor = MultiModalPredictor(\n",
    "        label='label',\n",
    "        problem_type='binary',\n",
    "        eval_metric='roc_auc',\n",
    "        validation_metric='roc_auc'\n",
    "    )\n",
    "    print(\"Predictor ìƒì„± ì„±ê³µ.\")\n",
    "except Exception as e:\n",
    "    print(\"MultiModalPredictor ìƒì„± ì—ëŸ¬:\", e)\n",
    "    predictor = None\n"
   ],
   "id": "db9cecf2ad74f915",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictor ìƒì„± ì„±ê³µ.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T21:55:03.784383Z",
     "start_time": "2025-02-28T03:22:56.920554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤.\n",
    "try:\n",
    "    if predictor is not None:\n",
    "        predictor.fit(\n",
    "            train_data=final_train,\n",
    "            column_types=column_types,\n",
    "            presets='best_quality',\n",
    "            time_limit=None,\n",
    "            seed=42,\n",
    "            hyperparameters={\n",
    "                \"model.hf_text.checkpoint_name\": \"r3ddkahili/final-complete-malicious-url-model\",\n",
    "                \"env.per_gpu_batch_size\": 64,\n",
    "                \"optimization.patience\": 10,\n",
    "                \"optimization.loss_function\": \"focal_loss\",\n",
    "                \"optimization.focal_loss.alpha\": weights,\n",
    "            }\n",
    "        )\n",
    "        print(\"ëª¨ë¸ í•™ìŠµ ì™„ë£Œ.\")\n",
    "\n",
    "        # ëª¨ë¸ ì €ì¥\n",
    "        predictor.save('../../models/malicious_url_model_with_entropy')\n",
    "        print(\"ëª¨ë¸ ì €ì¥ ì™„ë£Œ.\")\n",
    "    else:\n",
    "        print(\"Predictorê°€ Noneì…ë‹ˆë‹¤. ëª¨ë¸ í•™ìŠµ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "except Exception as e:\n",
    "    print(\"predictor.fit ì‹¤í–‰ ì¤‘ ì—ëŸ¬:\", e)\n"
   ],
   "id": "34ca9592a32ca28a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250228_032256\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          24\n",
      "Pytorch Version:    2.5.1+cu124\n",
      "CUDA Version:       12.4\n",
      "Memory Avail:       36.64 GB / 62.57 GB (58.6%)\n",
      "Disk Space Avail:   1527.60 GB / 1831.76 GB (83.4%)\n",
      "===================================================\n",
      "\n",
      "AutoMM starts to create your model. âœ¨âœ¨âœ¨\n",
      "\n",
      "To track the learning progress, you can open a terminal and launch Tensorboard:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir /home/lh/Documents/Malicious.URL.Detector/notebooks/inference/AutogluonModels/ag-20250228_032256\n",
      "    ```\n",
      "\n",
      "Seed set to 42\n",
      "GPU Count: 1\n",
      "GPU Count to be Used: 1\n",
      "GPU 0 Name: NVIDIA GeForce RTX 3090 Ti\n",
      "GPU 0 Memory: 1.44GB/23.99GB (Used/Total)\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                | Params | Mode \n",
      "------------------------------------------------------------------\n",
      "0 | model             | MultimodalFusionMLP | 111 M  | train\n",
      "1 | validation_metric | BinaryAUROC         | 0      | train\n",
      "2 | loss_func         | FocalLoss           | 0      | train\n",
      "------------------------------------------------------------------\n",
      "111 M     Trainable params\n",
      "0         Non-trainable params\n",
      "111 M     Total params\n",
      "444.975   Total estimated model params size (MB)\n",
      "82        Modules in train mode\n",
      "228       Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0061aa05aec0460685e2f9f44fa24544"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad672c64e49e4fdfb1b863400defb55f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3338e4b806a84e39b9ab4eaba5d10435"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 27051: 'val_roc_auc' reached 0.97932 (best 0.97932), saving model to '/home/lh/Documents/Malicious.URL.Detector/notebooks/inference/AutogluonModels/ag-20250228_032256/epoch=0-step=27051.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "59385a4decc74dda8e8bf82f17498db0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 54102: 'val_roc_auc' reached 0.98146 (best 0.98146), saving model to '/home/lh/Documents/Malicious.URL.Detector/notebooks/inference/AutogluonModels/ag-20250228_032256/epoch=0-step=54102.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "01edcca878ea44beb1d806b8527cbaed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 81154: 'val_roc_auc' reached 0.98178 (best 0.98178), saving model to '/home/lh/Documents/Malicious.URL.Detector/notebooks/inference/AutogluonModels/ag-20250228_032256/epoch=1-step=81154.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e82a7fbe95f740c2850cdcfe3500ec79"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 108205: 'val_roc_auc' reached 0.98260 (best 0.98260), saving model to '/home/lh/Documents/Malicious.URL.Detector/notebooks/inference/AutogluonModels/ag-20250228_032256/epoch=1-step=108205.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "434c522aa34a40ec9765e5b25379f9a4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 135257: 'val_roc_auc' reached 0.98191 (best 0.98260), saving model to '/home/lh/Documents/Malicious.URL.Detector/notebooks/inference/AutogluonModels/ag-20250228_032256/epoch=2-step=135257.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c42672457e0d4d879cd9263e07444301"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 162308: 'val_roc_auc' reached 0.98307 (best 0.98307), saving model to '/home/lh/Documents/Malicious.URL.Detector/notebooks/inference/AutogluonModels/ag-20250228_032256/epoch=2-step=162308.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "264a0b08766f43908666f85f6eb22356"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 189360: 'val_roc_auc' was not in top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2c8c1b016ab4998990c57eb9fa0e938"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 216411: 'val_roc_auc' was not in top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e2b42f88820940a3afd86cd15b6222a8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 243463: 'val_roc_auc' was not in top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "740688bdaa304038b5adfabf8d9afab8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 270514: 'val_roc_auc' was not in top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "31270fd926494efb8095e52bae1ffebe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 297566: 'val_roc_auc' was not in top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d879427129624f94879b2f3a8f3e8a4e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 324617: 'val_roc_auc' was not in top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8a9b19e8f21b4a099ed7026eadc86b31"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 351669: 'val_roc_auc' was not in top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e5f8a1c814c44c8f8433f01c8c8732a4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 378720: 'val_roc_auc' was not in top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad6f146d6aff4604aed0a9bf35a22630"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 405772: 'val_roc_auc' was not in top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f3218b506ff448ad81950dfb41333e51"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 432823: 'val_roc_auc' was not in top 3\n",
      "Start to fuse 3 checkpoints via the greedy soup algorithm.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4c896c95ea644878a6f88cde5bff0c47"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "395e0067146f47f5bb201384c42113d5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e738d320bb00416486e3ba9253a32b70"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AutoMM has created your model. ğŸ‰ğŸ‰ğŸ‰\n",
      "\n",
      "To load the model, use the code below:\n",
      "    ```python\n",
      "    from autogluon.multimodal import MultiModalPredictor\n",
      "    predictor = MultiModalPredictor.load(\"/home/lh/Documents/Malicious.URL.Detector/notebooks/inference/AutogluonModels/ag-20250228_032256\")\n",
      "    ```\n",
      "\n",
      "If you are not satisfied with the model, try to increase the training time, \n",
      "adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\n",
      "or post issues on GitHub (https://github.com/autogluon/autogluon/issues).\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ í•™ìŠµ ì™„ë£Œ.\n",
      "ëª¨ë¸ ì €ì¥ ì™„ë£Œ.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T21:55:03.803206Z",
     "start_time": "2025-02-28T21:55:03.800093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ëª¨ë¸ì˜ íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "try:\n",
    "    if predictor is not None:\n",
    "        feature_importance = predictor.feature_importance(final_train)\n",
    "        if feature_importance is not None:\n",
    "            print(\"\\níŠ¹ì„± ì¤‘ìš”ë„:\")\n",
    "            print(feature_importance.sort_values(by='importance', ascending=False).head(10))\n",
    "\n",
    "            # íŠ¹ì„± ì¤‘ìš”ë„ ì €ì¥\n",
    "            feature_importance.to_csv('../../data/feature_importance_with_entropy.csv')\n",
    "            print(\"íŠ¹ì„± ì¤‘ìš”ë„ ì €ì¥ ì™„ë£Œ.\")\n",
    "except Exception as e:\n",
    "    print(\"íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„ ì¤‘ ì—ëŸ¬:\", e)\n"
   ],
   "id": "b24a26d1757aa49b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„ ì¤‘ ì—ëŸ¬: 'MultiModalPredictor' object has no attribute 'feature_importance'\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T21:55:06.726218Z",
     "start_time": "2025-02-28T21:55:03.839105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.\n",
    "try:\n",
    "    if predictor is not None and 'label' in final_train.columns:\n",
    "        # ì¼ë¶€ ë°ì´í„°ë¡œ ëª¨ë¸ í‰ê°€\n",
    "        eval_data = final_train.sample(min(5000, len(final_train)), random_state=42)\n",
    "        eval_metrics = predictor.evaluate(eval_data)\n",
    "        print(\"\\nëª¨ë¸ í‰ê°€ ê²°ê³¼:\")\n",
    "        print(eval_metrics)\n",
    "except Exception as e:\n",
    "    print(\"ëª¨ë¸ í‰ê°€ ì¤‘ ì—ëŸ¬:\", e)\n"
   ],
   "id": "d73c444e08206f98",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9d75fac577a4663942a4051af1d4561"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ëª¨ë¸ í‰ê°€ ê²°ê³¼:\n",
      "{'roc_auc': 0.9952094072164949}\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T22:10:21.533953Z",
     "start_time": "2025-02-28T21:55:06.760583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ test ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ í™•ë¥ ì„ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "try:\n",
    "    if predictor is not None:\n",
    "        test_pred_proba = predictor.predict_proba(final_test)\n",
    "        # ì´ì§„ ë¶„ë¥˜ì˜ ê²½ìš°, í´ë˜ìŠ¤ 1(ì•…ì„± URL)ì˜ í™•ë¥  ì‚¬ìš©\n",
    "        if 1 in test_pred_proba.columns:\n",
    "            prediction_scores = test_pred_proba[1]\n",
    "        else:\n",
    "            prediction_scores = test_pred_proba.iloc[:, 1]\n",
    "        print(\"ì˜ˆì¸¡ ì™„ë£Œ.\")\n",
    "    else:\n",
    "        print(\"Predictorê°€ Noneì…ë‹ˆë‹¤. ê¸°ë³¸ 0 ì˜ˆì¸¡ê°’ ì‚¬ìš©.\")\n",
    "        prediction_scores = np.zeros(len(final_test))\n",
    "except Exception as e:\n",
    "    print(\"ì˜ˆì¸¡ ì‹¤í–‰ ì¤‘ ì—ëŸ¬:\", e)\n",
    "    prediction_scores = np.zeros(len(final_test))\n"
   ],
   "id": "b2b95fd2b918e4e6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "63811eb70de646f980258172b418238d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜ˆì¸¡ ì™„ë£Œ.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T23:14:51.313696Z",
     "start_time": "2025-03-03T23:14:50.455941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì œì¶œ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "try:\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': final_test['ID'],\n",
    "        'probability': prediction_scores\n",
    "    })\n",
    "    submission.to_csv('/home/lh/Documents/Malicious.URL.Detector/submission/FE_multimodal_ver2.csv', index=False)\n",
    "    print(\"\\nì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ.\")\n",
    "except Exception as e:\n",
    "    print(\"ì œì¶œ íŒŒì¼ ìƒì„± ì—ëŸ¬:\", e)\n"
   ],
   "id": "1b77094ca5fb0ab6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T22:10:21.851618Z",
     "start_time": "2025-02-28T22:10:21.607800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ì—”íŠ¸ë¡œí”¼ íŠ¹ì„±ì˜ íš¨ê³¼ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.\n",
    "try:\n",
    "    if 'label' in final_train.columns:\n",
    "        print(\"\\nì—”íŠ¸ë¡œí”¼ íŠ¹ì„±ê³¼ ë¼ë²¨ ê°„ì˜ ìƒê´€ê´€ê³„:\")\n",
    "        entropy_features = [col for col in final_train.columns if 'entropy' in col]\n",
    "\n",
    "        if entropy_features:\n",
    "            correlation = final_train[entropy_features + ['label']].corr()['label'].sort_values(ascending=False)\n",
    "            print(correlation)\n",
    "\n",
    "            # ì—”íŠ¸ë¡œí”¼ íŠ¹ì„±ê³¼ ë¼ë²¨ ê°„ì˜ ìƒê´€ê´€ê³„ ì €ì¥\n",
    "            correlation_df = pd.DataFrame({'feature': correlation.index, 'correlation': correlation.values})\n",
    "            correlation_df.to_csv('../../data/entropy_features_correlation.csv', index=False)\n",
    "            print(\"ì—”íŠ¸ë¡œí”¼ íŠ¹ì„± ìƒê´€ê´€ê³„ ì €ì¥ ì™„ë£Œ.\")\n",
    "except Exception as e:\n",
    "    print(\"ì—”íŠ¸ë¡œí”¼ íŠ¹ì„± íš¨ê³¼ ë¶„ì„ ì¤‘ ì—ëŸ¬:\", e)"
   ],
   "id": "2378c40fb39b25d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ì—”íŠ¸ë¡œí”¼ íŠ¹ì„±ê³¼ ë¼ë²¨ ê°„ì˜ ìƒê´€ê´€ê³„:\n",
      "label                1.000000\n",
      "url_entropy          0.504389\n",
      "path_entropy         0.490501\n",
      "subdomain_entropy    0.414697\n",
      "Name: label, dtype: float64\n",
      "ì—”íŠ¸ë¡œí”¼ íŠ¹ì„± ìƒê´€ê´€ê³„ ì €ì¥ ì™„ë£Œ.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T22:10:21.861891Z",
     "start_time": "2025-02-28T22:10:21.860751Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "dfcb09a7f1f1ecf3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}

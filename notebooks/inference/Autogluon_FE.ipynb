{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T03:10:21.264487Z",
     "start_time": "2025-02-24T03:10:18.644943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from autogluon.multimodal import MultiModalPredictor\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ],
   "id": "8ba34e8ec13fc339",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T03:10:25.926460Z",
     "start_time": "2025-02-24T03:10:21.270499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ë°ì´í„°ë¥¼ CSV íŒŒì¼ì—ì„œ ì½ì–´ì˜µë‹ˆë‹¤.\n",
    "try:\n",
    "    final_train = pd.read_csv('../../data/preprocessed_data/final_train.csv')\n",
    "    final_test = pd.read_csv('../../data/preprocessed_data/final_test.csv')\n",
    "    print(\"ë°ì´í„° ë¡œë“œ ì„±ê³µ.\")\n",
    "except Exception as e:\n",
    "    print(\"ë°ì´í„° ë¡œë“œ ì—ëŸ¬:\", e)\n",
    "    final_train = pd.DataFrame()\n",
    "    final_test = pd.DataFrame()\n"
   ],
   "id": "d36f133bc5d1242b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ë¡œë“œ ì„±ê³µ.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T03:10:25.966921Z",
     "start_time": "2025-02-24T03:10:25.964946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ê° ì»¬ëŸ¼ì˜ íƒ€ì…ì„ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "try:\n",
    "    column_types = {\n",
    "       'URL': 'text',\n",
    "       'label': 'categorical',\n",
    "       'digit_ratio': 'numerical',\n",
    "       'special_char_count': 'numerical',\n",
    "       'subdomain_count': 'numerical',\n",
    "       'length': 'numerical'\n",
    "    }\n",
    "    print(\"ì»¬ëŸ¼ íƒ€ì… ì„¤ì • ì„±ê³µ.\")\n",
    "except Exception as e:\n",
    "    print(\"ì»¬ëŸ¼ íƒ€ì… ì„¤ì • ì—ëŸ¬:\", e)\n",
    "    column_types = {}\n"
   ],
   "id": "8e55a4088d6c63bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì»¬ëŸ¼ íƒ€ì… ì„¤ì • ì„±ê³µ.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T03:10:26.434613Z",
     "start_time": "2025-02-24T03:10:26.010964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train ë°ì´í„°ì˜ 'label' ì»¬ëŸ¼ì„ ê¸°ì¤€ìœ¼ë¡œ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ë¥¼ ê³„ì‚°í•˜ê³  ì •ê·œí™”í•©ë‹ˆë‹¤.\n",
    "try:\n",
    "    weights = compute_class_weight(\n",
    "       class_weight='balanced',\n",
    "       classes=np.unique(final_train['label']),\n",
    "       y=final_train['label'].values\n",
    "    )\n",
    "    weights = weights / weights.sum()  # ê°€ì¤‘ì¹˜ ì •ê·œí™” (í•©ê³„ 1)\n",
    "    weights = list(weights)\n",
    "    print(\"\\nê³„ì‚°ëœ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜:\", weights)\n",
    "except Exception as e:\n",
    "    print(\"í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° ì—ëŸ¬:\", e)\n",
    "    weights = []\n"
   ],
   "id": "8971ffa686c94c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ê³„ì‚°ëœ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜: [0.2237147207970887, 0.7762852792029113]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T03:10:26.441988Z",
     "start_time": "2025-02-24T03:10:26.440068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# AutoGluon MultiModalPredictorë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "try:\n",
    "    predictor = MultiModalPredictor(\n",
    "       label='label',\n",
    "       problem_type='binary',\n",
    "       eval_metric='roc_auc',\n",
    "       validation_metric='roc_auc'\n",
    "    )\n",
    "    print(\"Predictor ìƒì„± ì„±ê³µ.\")\n",
    "except Exception as e:\n",
    "    print(\"MultiModalPredictor ìƒì„± ì—ëŸ¬:\", e)\n",
    "    predictor = None\n"
   ],
   "id": "ce5b796dfa6aa831",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictor ìƒì„± ì„±ê³µ.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T15:46:56.772692Z",
     "start_time": "2025-02-24T03:10:26.484135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤.\n",
    "try:\n",
    "    if predictor is not None:\n",
    "        predictor.fit(\n",
    "           train_data=final_train,\n",
    "           column_types=column_types,\n",
    "           presets='best_quality',\n",
    "           time_limit=None,\n",
    "           seed=42,\n",
    "           hyperparameters={\n",
    "              \"model.hf_text.checkpoint_name\": \"r3ddkahili/final-complete-malicious-url-model\",\n",
    "              \"env.per_gpu_batch_size\": 64,\n",
    "              \"optimization.patience\": 5,\n",
    "              \"optimization.loss_function\": \"focal_loss\",\n",
    "              \"optimization.focal_loss.alpha\": weights,\n",
    "           }\n",
    "        )\n",
    "        print(\"ëª¨ë¸ í•™ìŠµ ì™„ë£Œ.\")\n",
    "    else:\n",
    "        print(\"Predictorê°€ Noneì…ë‹ˆë‹¤. ëª¨ë¸ í•™ìŠµ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "except Exception as e:\n",
    "    print(\"predictor.fit ì‹¤í–‰ ì¤‘ ì—ëŸ¬:\", e)\n"
   ],
   "id": "1d003f327fdb2ef2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250224_031026\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          24\n",
      "Pytorch Version:    2.5.1+cu124\n",
      "CUDA Version:       12.4\n",
      "Memory Avail:       52.25 GB / 62.57 GB (83.5%)\n",
      "Disk Space Avail:   1530.74 GB / 1831.76 GB (83.6%)\n",
      "===================================================\n",
      "\n",
      "AutoMM starts to create your model. âœ¨âœ¨âœ¨\n",
      "\n",
      "To track the learning progress, you can open a terminal and launch Tensorboard:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir /home/lh/Documents/Malicious.URL.Detector/notebooks/inference/AutogluonModels/ag-20250224_031026\n",
      "    ```\n",
      "\n",
      "Seed set to 42\n",
      "GPU Count: 1\n",
      "GPU Count to be Used: 1\n",
      "GPU 0 Name: NVIDIA GeForce RTX 3090 Ti\n",
      "GPU 0 Memory: 0.61GB/23.99GB (Used/Total)\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                | Params | Mode \n",
      "------------------------------------------------------------------\n",
      "0 | model             | MultimodalFusionMLP | 111 M  | train\n",
      "1 | validation_metric | BinaryAUROC         | 0      | train\n",
      "2 | loss_func         | FocalLoss           | 0      | train\n",
      "------------------------------------------------------------------\n",
      "111 M     Trainable params\n",
      "0         Non-trainable params\n",
      "111 M     Total params\n",
      "444.971   Total estimated model params size (MB)\n",
      "82        Modules in train mode\n",
      "228       Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33fb048305d9462cab27f2469c835e53"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "62a872a898364a8a8ac59d3e1b5cf203"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7b298a205f8d419eb397d271338ff858"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 27051: 'val_roc_auc' reached 0.97931 (best 0.97931), saving model to '/home/lh/Documents/Malicious.URL.Detector/notebooks/inference/AutogluonModels/ag-20250224_031026/epoch=0-step=27051.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c97666cf99ad42f0a9cad8fcebac71d1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 54102: 'val_roc_auc' reached 0.98090 (best 0.98090), saving model to '/home/lh/Documents/Malicious.URL.Detector/notebooks/inference/AutogluonModels/ag-20250224_031026/epoch=0-step=54102.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2bfa286c0e6c47ad93c0cdbc08710874"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 81154: 'val_roc_auc' reached 0.98175 (best 0.98175), saving model to '/home/lh/Documents/Malicious.URL.Detector/notebooks/inference/AutogluonModels/ag-20250224_031026/epoch=1-step=81154.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1bfb5fa0993e440ab8c2cc481fec8200"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 108205: 'val_roc_auc' reached 0.98264 (best 0.98264), saving model to '/home/lh/Documents/Malicious.URL.Detector/notebooks/inference/AutogluonModels/ag-20250224_031026/epoch=1-step=108205.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6207b3f4dc53490fad17f24e46d8b451"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 135257: 'val_roc_auc' reached 0.98208 (best 0.98264), saving model to '/home/lh/Documents/Malicious.URL.Detector/notebooks/inference/AutogluonModels/ag-20250224_031026/epoch=2-step=135257.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "972532a3214f42fcb8b6da65dd7da29c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 162308: 'val_roc_auc' reached 0.98265 (best 0.98265), saving model to '/home/lh/Documents/Malicious.URL.Detector/notebooks/inference/AutogluonModels/ag-20250224_031026/epoch=2-step=162308.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "781d9330ff6c4f1288a94faed5f654d1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 189360: 'val_roc_auc' was not in top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a028da3093f43678ebe344785c27574"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 216411: 'val_roc_auc' was not in top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fee1c6638582426ea92a1624cb9d8d2b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 243463: 'val_roc_auc' was not in top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "624baf3b725b421599d71fd29eafa5af"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 270514: 'val_roc_auc' was not in top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "84dfbd1fa7c44c7cbcf20ffc34e9cac8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 297566: 'val_roc_auc' was not in top 3\n",
      "Start to fuse 3 checkpoints via the greedy soup algorithm.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5264b6255bf6420dae170013907262e8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e523840a99d6403789a21b80782f9f7a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85bbd2ab0283484c8d496d9a9a2809fb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AutoMM has created your model. ğŸ‰ğŸ‰ğŸ‰\n",
      "\n",
      "To load the model, use the code below:\n",
      "    ```python\n",
      "    from autogluon.multimodal import MultiModalPredictor\n",
      "    predictor = MultiModalPredictor.load(\"/home/lh/Documents/Malicious.URL.Detector/notebooks/inference/AutogluonModels/ag-20250224_031026\")\n",
      "    ```\n",
      "\n",
      "If you are not satisfied with the model, try to increase the training time, \n",
      "adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\n",
      "or post issues on GitHub (https://github.com/autogluon/autogluon/issues).\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ í•™ìŠµ ì™„ë£Œ.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T16:01:53.034555Z",
     "start_time": "2025-02-24T15:46:56.785039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ test ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ í™•ë¥ ì„ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "try:\n",
    "    if predictor is not None:\n",
    "        test_pred_proba = predictor.predict_proba(final_test)\n",
    "        # ì´ì§„ ë¶„ë¥˜ì˜ ê²½ìš°, í´ë˜ìŠ¤ 1(ì•…ì„± URL)ì˜ í™•ë¥  ì‚¬ìš©\n",
    "        if 1 in test_pred_proba.columns:\n",
    "            prediction_scores = test_pred_proba[1]\n",
    "        else:\n",
    "            prediction_scores = test_pred_proba.iloc[:, 1]\n",
    "        print(\"ì˜ˆì¸¡ ì™„ë£Œ.\")\n",
    "    else:\n",
    "        print(\"Predictorê°€ Noneì…ë‹ˆë‹¤. ê¸°ë³¸ 0 ì˜ˆì¸¡ê°’ ì‚¬ìš©.\")\n",
    "        prediction_scores = np.zeros(len(final_test))\n",
    "except Exception as e:\n",
    "    print(\"ì˜ˆì¸¡ ì‹¤í–‰ ì¤‘ ì—ëŸ¬:\", e)\n",
    "    prediction_scores = np.zeros(len(final_test))\n"
   ],
   "id": "f49c76a1acb0a354",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ede6b71b64e0470b9a31b23d95b8f467"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜ˆì¸¡ ì™„ë£Œ.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T16:01:53.894661Z",
     "start_time": "2025-02-24T16:01:53.048846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì œì¶œ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "try:\n",
    "    submission = pd.DataFrame({\n",
    "       'ID': final_test['ID'],\n",
    "       'probability': prediction_scores\n",
    "    })\n",
    "    submission.to_csv('../../submission/FE_multimodal2.csv', index=False)\n",
    "    print(\"\\nì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ.\")\n",
    "except Exception as e:\n",
    "    print(\"ì œì¶œ íŒŒì¼ ìƒì„± ì—ëŸ¬:\", e)\n"
   ],
   "id": "2fb3ce687553456",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ.\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
